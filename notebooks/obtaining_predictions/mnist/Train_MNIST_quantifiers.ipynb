{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "full_x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "full_x_train /= 255\n",
    "x_test /= 255\n",
    "x_valid = full_x_train[-10000:]\n",
    "print('x_train shape:', full_x_train.shape)\n",
    "print(full_x_train.shape[0], 'train samples')\n",
    "print(x_valid.shape[0], 'valid samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "full_y_train = y_train\n",
    "y_valid = y_train[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/nas/pgonzalez/DLquantification')\n",
    "from histnet.histnet import HistNet\n",
    "import torch\n",
    "from histnet.featureextraction.fullyconnected import FCFeatureExtractionModule\n",
    "from histnet.utils.utils import QLibPriorShiftBagGenerator\n",
    "from torch.utils.data import TensorDataset\n",
    "from histnet.utils.lossfunc import MRAE\n",
    "\n",
    "model_files = []\n",
    "device=torch.device('cuda:0')\n",
    "\n",
    "loss_mrae = MRAE(eps=1.0 / (2 * 500)).MRAE\n",
    "\n",
    "for seed in range(0,100,10):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    for model_idx,train_set_size in enumerate([30000]):\n",
    "        x_train = full_x_train[:train_set_size] \n",
    "        y_train = full_y_train[:train_set_size]\n",
    "        print(y_train.shape)\n",
    "        print(y_valid.shape)\n",
    "        train_dset = TensorDataset(\n",
    "            torch.cat((torch.from_numpy(x_train),torch.from_numpy(x_valid))),\n",
    "            torch.cat((torch.from_numpy(y_train),torch.from_numpy(y_valid)))\n",
    "        )\n",
    "\n",
    "  \n",
    "        print(\"Using %d for training and %d for validation\"%(len(y_train),len(y_valid)))\n",
    "        train_bag_generator = QLibPriorShiftBagGenerator(device, method=\"Dirichlet\", alphas=1)\n",
    "        val_bag_generator = QLibPriorShiftBagGenerator(device, method=\"Dirichlet\", alphas=1)\n",
    "\n",
    "        model_file = \"model_quant_mnist_mse_set-\"+str(train_set_size)+\"_mse_seed-\"+str(seed)+\".h5\"\n",
    "        model_files.append(model_file)\n",
    "        fe = FCFeatureExtractionModule(input_size=784, output_size=128, hidden_sizes=[256], dropout=0, activation=\"relu\",flatten=True)\n",
    "        model = HistNet(train_epochs = 1000, test_epochs = 1, batch_size=100, n_classes = 10, start_lr = 0.001, \n",
    "            end_lr = 0.00001, n_bags = 5000, histogram=\"softrbf\", bag_size=1000,n_bins=32, random_seed=seed,linear_sizes=[512],\n",
    "            feature_extraction_module=fe,bag_generator=train_bag_generator,patience=10,\n",
    "            quant_loss=torch.nn.MSELoss(),\n",
    "            dropout=0.5,\n",
    "            val_bag_generator=val_bag_generator,\n",
    "            val_split=(range(0,train_set_size),range(train_set_size,train_set_size+10000)),verbose=10,dataset_name=\"minst\",device=device,\n",
    "            save_model_path=model_file\n",
    "            )\n",
    "        model.fit(train_dset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "gist - Download CIFAR10 models from zenodo and make predictions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "interpreter": {
   "hash": "4fba9110b1a4ec95baa236356b4366c963be065d6fde289654bed570a6fc51de"
  },
  "kernelspec": {
   "display_name": "Python [conda env:basepair]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
